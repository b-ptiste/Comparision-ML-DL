{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for DL\n",
    "from keras import Sequential, layers\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import time\n",
    "import time\n",
    "\n",
    "# for visulisation \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup\n",
    "num_train = 5000*4\n",
    "num_test  = 500*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for CNN\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "num_of_units = 256\n",
    "\n",
    "# Creating a list of all the class labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for i in range (25):    # for first 25 images\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i][0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be15733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the pixels data to float type\n",
    "\n",
    "x_train = x_train[:num_train,:,:,:]\n",
    "y_train = y_train[:num_train,:]\n",
    "\n",
    "x_test = x_test[:num_test,:,:,:]\n",
    "y_test = y_test[:num_test,:]\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    " \n",
    "# Standardizing (255 is the total number of pixels an image can have)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255 \n",
    "\n",
    "# One hot encoding the target class (labels)\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c96c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"val_accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211339e",
   "metadata": {},
   "source": [
    "# change padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31564648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='valid', activation='relu', input_shape=(32,32,3)))\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace66585",
   "metadata": {},
   "source": [
    "# Add batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ba6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3cc63",
   "metadata": {},
   "source": [
    "# Use Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f23b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9972060",
   "metadata": {},
   "source": [
    "# Delete Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f546905",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da31bf",
   "metadata": {},
   "source": [
    "# change the size of the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7846335",
   "metadata": {},
   "source": [
    "here for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "map_score_kernel = {}\n",
    "for i in range(3,6):\n",
    "    for j in range(2,4):\n",
    "        model = Sequential()\n",
    "\n",
    "        # first convolutional layer\n",
    "        model.add(layers.Conv2D(32, (i,i), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "        # second convolutional layer\n",
    "        model.add(layers.Conv2D(32, (i,i), padding='same', activation='relu'))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(j,j)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        # fully connected part\n",
    "\n",
    "        # third part\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        # fourth part\n",
    "        model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        # prediction\n",
    "        model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-6)\n",
    "        model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        t1 = time.time()\n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                            validation_data=(x_test, y_test))\n",
    "        t2 = time.time()-t1\n",
    "        pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "        pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "        map_score_kernel[f\"{i}-{j}\"] = t2, history.history[\"accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b908993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kernel = pd.DataFrame(index=map_score_kernel.keys(), data = map_score_kernel.values(), columns=[\"time\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978612dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kernel[\"time\"].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718645b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kernel[\"accuracy\"].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442ab00",
   "metadata": {},
   "source": [
    "# add layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32154c00",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6127db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sequential model and adding layers to it\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfa5c1",
   "metadata": {},
   "source": [
    "## fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sequential model and adding layers to it\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fifth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a68915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b654cf",
   "metadata": {},
   "source": [
    "# add layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sequential model and adding layers to it\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "print(t2)\n",
    "print(history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c87b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b3020",
   "metadata": {},
   "source": [
    "# change epochs and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_size = [16, 32, 64]\n",
    "num_epochs = 20\n",
    "num_of_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faffebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score_batch = {}\n",
    "for batch_size in list_batch_size:\n",
    "    model = Sequential()\n",
    "\n",
    "    # first convolutional layer\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "    # second convolutional layer\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    # fully connected part\n",
    "\n",
    "    # third part\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # fourth part\n",
    "    model.add(layers.Dense(num_of_units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # prediction\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "    model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    t1 = time.time()\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "    pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "    t2 = time.time()-t1\n",
    "    map_score_batch[f\"{batch_size}\"] = t2,history.history[\"accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc965273",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac97ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batchs = pd.DataFrame(index=map_score_batch.keys(), data = map_score_batch.values(), columns=[\"time\", \"accuracy\"])\n",
    "df_batchs[\"time\"].plot()\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1405b",
   "metadata": {},
   "source": [
    "# number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_size = 32\n",
    "num_epochs = 10\n",
    "num_of_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neuron_conv = [128, 256]\n",
    "list_neuron_fully = [32, 64, 128, 256]\n",
    "map_score_neurons = {}\n",
    "for i in range(len(list_neuron_conv)-1):\n",
    "    for j in range(len(list_neuron_fully)-1):\n",
    "        model = Sequential()\n",
    "\n",
    "        # first convolutional layer\n",
    "        model.add(layers.Conv2D(list_neuron_conv[i], (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "        # second convolutional layer\n",
    "        model.add(layers.Conv2D(list_neuron_conv[i+1], (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        # fully connected part\n",
    "\n",
    "        # third part\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(list_neuron_fully[j], activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        # fourth part\n",
    "        model.add(layers.Dense(list_neuron_fully[j+1], activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        # prediction\n",
    "        model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-6)\n",
    "        model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        t1 = time.time()\n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                            validation_data=(x_test, y_test))\n",
    "        t2 = time.time()-t1\n",
    "        pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "        pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "        map_score_neurons[f\"{list_neuron_conv[i]} - {list_neuron_conv[i+1]} - {list_neuron_fully[j]} - {list_neuron_fully[j+1]}\"] = t2, history.history[\"accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neurons = pd.DataFrame(index=map_score_neurons.keys(), data = map_score_neurons.values(), columns=[\"time\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f13db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neurons[\"time\"].plot()\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f47fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neurons[\"accuracy\"].plot()\n",
    "plt.xticks(rotation=45) \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469d4e1",
   "metadata": {},
   "source": [
    "# Best model with batch normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657bbbc",
   "metadata": {},
   "source": [
    "## /!\\ You should load all the training dataset and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0890fd",
   "metadata": {},
   "source": [
    "# Best model without batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# fully connected part\n",
    "\n",
    "# third part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# fourth part\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# prediction\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001, epsilon=1e-6)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test))\n",
    "t2 = time.time()-t1\n",
    "pd.DataFrame(history.history)[[\"loss\",\"val_loss\"]].plot()\n",
    "pd.DataFrame(history.history)[[\"accuracy\",\"val_accuracy\"]].plot()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
